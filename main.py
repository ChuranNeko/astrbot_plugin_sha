from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
from astrbot.api import logger, AstrBotConfig
import aiohttp
import ssl
import certifi
import re
import os
import json
import time
from typing import List, Dict, Any
from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import (
    AiocqhttpMessageEvent,
)
from astrbot.api.star import StarTools


@register(
    "astrbot_plugin_sha",
    "IGCrystal",
    "è·å–GitHubä»“åº“æœ€å5æ¬¡æäº¤SHAçš„æ’ä»¶",
    "1.3.0",
    "https://github.com/IGCrystal-NEO/astrbot_plugin_sha",
)
class GitHubShaPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        # å¾…å®¡ç¼“å­˜ï¼š{ group_id: { user_id: {flag, sub_type, comment, ts} } }
        self._pending_cache: Dict[str, Dict[str, Dict[str, Any]]] = {}
        self._data_dir = str(StarTools.get_data_dir("astrbot_plugin_sha"))
        self._pending_path = os.path.join(self._data_dir, "pending_group_requests.json")

    async def initialize(self):
        try:
            os.makedirs(self._data_dir, exist_ok=True)
            if os.path.exists(self._pending_path):
                with open(self._pending_path, "r", encoding="utf-8") as f:
                    self._pending_cache = json.load(f)
        except Exception as e:
            logger.error(f"[å®¡é˜…åŠ ç¾¤] åŠ è½½å¾…å®¡ç¼“å­˜å¤±è´¥: {e}")

    def _save_pending_cache(self) -> None:
        try:
            with open(self._pending_path, "w", encoding="utf-8") as f:
                json.dump(self._pending_cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"[å®¡é˜…åŠ ç¾¤] ä¿å­˜å¾…å®¡ç¼“å­˜å¤±è´¥: {e}")

    def _remember_request(self, group_id: str, user_id: str, flag: str, sub_type: str, comment: str) -> None:
        group_id = str(group_id)
        user_id = str(user_id)
        self._pending_cache.setdefault(group_id, {})[user_id] = {
            "flag": flag,
            "sub_type": sub_type,
            "comment": comment or "",
            "ts": int(time.time()),
        }
        # æ¸…ç†è¶…è¿‡48å°æ—¶çš„æ¡ç›®
        expire_before = int(time.time()) - 48 * 3600
        for gid in list(self._pending_cache.keys()):
            for uid in list(self._pending_cache[gid].keys()):
                if int(self._pending_cache[gid][uid].get("ts", 0)) < expire_before:
                    del self._pending_cache[gid][uid]
            if not self._pending_cache[gid]:
                del self._pending_cache[gid]
        self._save_pending_cache()

    def _get_cached_request(self, group_id: str, user_id: str) -> Dict[str, Any] | None:
        return self._pending_cache.get(str(group_id), {}).get(str(user_id))

    def _qqadmin_group_join_data_path(self) -> str:
        return os.path.join(str(StarTools.get_data_dir("astrbot_plugin_QQAdmin")), "group_join_data.json")

    def _load_group_join_blacklist(self) -> Dict[str, Any]:
        try:
            path = self._qqadmin_group_join_data_path()
            if os.path.exists(path):
                with open(path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    return data or {}
        except Exception as e:
            logger.error(f"[å®¡é˜…åŠ ç¾¤] è¯»å–é»‘åå•å¤±è´¥: {e}")
        return {}

    def _is_blacklisted(self, group_id: str, user_id: str) -> bool:
        data = self._load_group_join_blacklist()
        reject_ids: Dict[str, List[str]] = data.get("reject_ids", {})
        group_list = reject_ids.get(str(group_id), []) or []
        return str(user_id) in {str(x) for x in group_list}

    # ===== Helper methods for reuse =====
    def _get_repo_cfg(self) -> tuple[str, str, int]:
        github_repo = self.config.get("github_repo", "AstrBotDevs/AstrBot")
        branch = self.config.get("branch", "master")
        commit_count = self.config.get("commit_count", 5)
        return github_repo, branch, commit_count

    def _is_group_admin(self, event: AiocqhttpMessageEvent, group) -> bool:
        if not group:
            return False
        self_id = str(event.get_self_id())
        admin_ids = [str(x) for x in (group.group_admins or [])]
        owner_id = str(group.group_owner) if group.group_owner else None
        return self_id in admin_ids or (owner_id and self_id == owner_id)

    @staticmethod
    def _match_sha_prefixes(candidates: List[str], recent_shas: List[str]) -> tuple[bool, str | None]:
        for cand in candidates:
            if len(cand) >= 7 and any(s.startswith(cand) for s in recent_shas):
                return True, cand
        return False, None

    def _format_summary(self, approved: int, rejected: int, skipped_blacklist: int, details: List[str]) -> str:
        if approved == 0 and rejected == 0:
            if details:
                return "\n".join(details)
            msg = "æ²¡æœ‰å¯å®¡é˜…çš„åŠ ç¾¤ç”³è¯·"
            if skipped_blacklist:
                msg += f"ï¼ˆå«é»‘åå•è·³è¿‡ {skipped_blacklist} é¡¹ï¼‰"
            return msg
        prefix = f"å®¡é˜…å®Œæˆï¼šæ‰¹å‡† {approved} é¡¹ï¼Œæ‹’ç» {rejected} é¡¹"
        if skipped_blacklist:
            prefix += f"ï¼Œè·³è¿‡ {skipped_blacklist} é¡¹ï¼ˆé»‘åå•ï¼‰"
        return prefix + ("\n" + "\n".join(details) if details else "")

    @filter.regex(r"(?i)^sha$")
    async def on_sha_keyword(self, event: AstrMessageEvent):
        """å…¨å±€ç›‘å¬ï¼šæ¶ˆæ¯ä¸­åŒ…å« 'sha' æ—¶è§¦å‘ï¼ˆä¸ä¾èµ–å”¤é†’å‰ç¼€ï¼‰"""
        # é¿å…ä¸æŒ‡ä»¤é‡å¤ï¼ˆå¦‚ /shaï¼‰ï¼Œè‹¥æ˜¯ä»¥æŒ‡ä»¤å½¢å¼ï¼Œåˆ™äº¤ç»™æŒ‡ä»¤å¤„ç†
        msg = (event.message_str or "").strip()
        if msg.startswith("/"):
            return
        async for res in self.get_github_sha(event):
            yield res

    @filter.command("sha")
    async def get_github_sha(self, event: AstrMessageEvent):
        """è·å–GitHubä»“åº“æŒ‡å®šåˆ†æ”¯çš„æœ€æ–°æäº¤SHA"""
        try:
            github_repo, branch, commit_count = self._get_repo_cfg()
            github_api_url = f"https://api.github.com/repos/{github_repo}/commits"

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œå¦‚æœæ˜¯åˆ™æé†’ç”¨æˆ·
            if github_repo == "AstrBotDevs/AstrBot":
                reminder_msg = (
                    f"ğŸ“Œ å½“å‰ä½¿ç”¨é»˜è®¤ä»“åº“: {github_repo}\n"
                    "ğŸ’¡ æç¤º: å¯åœ¨æ’ä»¶ç®¡ç†é¡µé¢é…ç½®å…¶ä»–GitHubä»“åº“åœ°å€\n"
                    "æ ¼å¼: owner/repo (ä¾‹å¦‚: microsoft/vscode)\n\n"
                )
                yield event.plain_result(reminder_msg)

            logger.debug(f"å¼€å§‹è·å– {github_repo} ä»“åº“çš„æäº¤SHA...")

            # SSL: ä½¿ç”¨ certifi CAï¼Œé¿å…æœåŠ¡å™¨ç¼ºå°‘ç³»ç»Ÿæ ¹è¯ä¹¦å¯¼è‡´çš„æ ¡éªŒå¤±è´¥
            ssl_ctx = ssl.create_default_context(cafile=certifi.where())

            # ä»GitHub APIè·å–æŒ‡å®šæ•°é‡çš„æäº¤
            connector = aiohttp.TCPConnector(ssl=ssl_ctx)
            async with aiohttp.ClientSession(connector=connector) as session:
                params = {"sha": branch, "per_page": commit_count}

                async with session.get(github_api_url, params=params) as response:
                    if response.status == 200:
                        commits = await response.json()

                        if not commits:
                            yield event.plain_result("âŒ æœªæ‰¾åˆ°ä»»ä½•æäº¤è®°å½•")
                            return

                        # æ„å»ºå›å¤æ¶ˆæ¯
                        result_lines = [
                            f"ğŸ” {github_repo} ä»“åº“ ({branch} åˆ†æ”¯) æœ€å{commit_count}æ¬¡æäº¤ SHAï¼š\n"
                        ]

                        for i, commit in enumerate(commits, 1):
                            sha = commit["sha"]  # æ˜¾ç¤ºå®Œæ•´çš„SHA
                            message = commit["commit"]["message"].split("\n")[
                                0
                            ]  # åªå–ç¬¬ä¸€è¡Œæäº¤ä¿¡æ¯
                            author = commit["commit"]["author"]["name"]
                            date = commit["commit"]["author"]["date"][
                                :10
                            ]  # åªå–æ—¥æœŸéƒ¨åˆ†

                            result_lines.append(f"{i}. {sha} - {message}")
                            result_lines.append(f"   ä½œè€…: {author} | æ—¥æœŸ: {date}\n")

                        result_text = "\n".join(result_lines)
                        yield event.plain_result(result_text)

                        logger.debug(f"æˆåŠŸè·å– {github_repo} çš„GitHubæäº¤SHA")

                    else:
                        error_msg = f"GitHub API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}"
                        logger.error(error_msg)
                        yield event.plain_result(f"âŒ {error_msg}")

        except aiohttp.ClientError as e:
            error_msg = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}"
            logger.error(error_msg)
            yield event.plain_result(f"âŒ {error_msg}")

        except Exception as e:
            error_msg = f"è·å–æäº¤SHAæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(error_msg)
            yield event.plain_result(f"âŒ {error_msg}")

    async def _fetch_recent_commit_shas(self) -> List[str]:
        """è¿”å›æœ€è¿‘é…ç½®æ•°é‡çš„æäº¤ SHA åˆ—è¡¨ï¼ˆå®Œæ•´ 40 ä½ï¼‰ã€‚"""
        github_repo = self.config.get("github_repo", "AstrBotDevs/AstrBot")
        branch = self.config.get("branch", "master")
        commit_count = self.config.get("commit_count", 5)
        github_api_url = f"https://api.github.com/repos/{github_repo}/commits"

        ssl_ctx = ssl.create_default_context(cafile=certifi.where())
        connector = aiohttp.TCPConnector(ssl=ssl_ctx)
        async with aiohttp.ClientSession(connector=connector) as session:
            params = {"sha": branch, "per_page": commit_count}
            async with session.get(github_api_url, params=params) as response:
                if response.status != 200:
                    raise RuntimeError(
                        f"GitHub API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}"
                    )
                commits = await response.json()
                return [c["sha"] for c in commits if "sha" in c]

    @staticmethod
    def _extract_sha_candidates(text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å¯èƒ½çš„ SHA å‰ç¼€ï¼ˆè‡³å°‘7ä½ï¼‰ã€‚"""
        if not text:
            return []
        candidates = re.findall(r"\b[a-fA-F0-9]{7,40}\b", text)
        # ç»Ÿä¸€å°å†™ï¼Œå»é‡
        dedup = []
        for c in candidates:
            c = c.lower()
            if c not in dedup:
                dedup.append(c)
        return dedup

    @filter.platform_adapter_type(filter.PlatformAdapterType.AIOCQHTTP)
    @filter.event_message_type(filter.EventMessageType.GROUP_MESSAGE)
    @filter.command("å®¡é˜…åŠ ç¾¤")
    async def review_group_requests(self, event: AiocqhttpMessageEvent):
        """å®¡é˜…å¾…å¤„ç†çš„åŠ ç¾¤è¯·æ±‚ï¼Œä¾æ®ç”³è¯·ä¿¡æ¯ä¸­çš„ SHA å‰ç¼€è‡ªåŠ¨æ‰¹å‡†æˆ–æ‹’ç»ã€‚"""
        try:
            group = await event.get_group()
            if not group:
                yield event.plain_result("ä»…æ”¯æŒåœ¨ç¾¤èŠä¸­ä½¿ç”¨è¯¥æŒ‡ä»¤")
                return

            self_id = str(event.get_self_id())
            admin_ids = [str(x) for x in (group.group_admins or [])]
            owner_id = str(group.group_owner) if group.group_owner else None
            is_admin = self_id in admin_ids or (owner_id and self_id == owner_id)
            logger.debug(
                f"[å®¡é˜…åŠ ç¾¤] group_id={group.group_id}, self_id={self_id}, owner_id={owner_id}, "
                f"admin_ids_len={len(admin_ids)}, is_admin={is_admin}"
            )
            if not is_admin:
                yield event.plain_result("æˆ‘ä¸æ˜¯æœ¬ç¾¤ç®¡ç†å‘˜ï¼Œæ— æ³•å®¡é˜…åŠ ç¾¤ç”³è¯·")
                return

            # è·å–æœ€è¿‘æäº¤çš„ SHA åˆ—è¡¨
            try:
                recent_shas = [s.lower() for s in await self._fetch_recent_commit_shas()]
                logger.debug(
                    f"[å®¡é˜…åŠ ç¾¤] recent_shas_count={len(recent_shas)}, sample={[s[:10] for s in recent_shas[:5]]}"
                )
            except Exception as e:
                logger.error(f"è·å–ä»“åº“æäº¤åˆ—è¡¨å¤±è´¥: {e}")
                yield event.plain_result("è·å–ä»“åº“æäº¤åˆ—è¡¨å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
                return

            # ä»…ä»ç¼“å­˜è¯»å–å¾…å®¡è¯·æ±‚ï¼ˆå‚è€ƒ QQAdmin äº‹ä»¶æµï¼‰
            grp_id = str(event.get_group_id())
            pending_map: Dict[str, Dict[str, Any]] = dict(self._pending_cache.get(grp_id, {}))
            logger.debug(
                f"[å®¡é˜…åŠ ç¾¤] use cache only, pending_count={len(pending_map)} for group={grp_id}"
            )

            if not pending_map:
                yield event.plain_result("æ²¡æœ‰å¾…å®¡çš„åŠ ç¾¤ç”³è¯·")
                return

            results: List[str] = []
            approved = 0
            rejected = 0
            skipped_blacklist = 0

            for user_id, info in pending_map.items():
                # é»‘åå•ç›´æ¥è·³è¿‡ä¸å®¡é˜…
                if self._is_blacklisted(grp_id, user_id):
                    skipped_blacklist += 1
                    logger.debug(f"[å®¡é˜…åŠ ç¾¤] skip user={user_id} by blacklist for group={grp_id}")
                    continue
                flag = info.get("flag")
                sub_type = info.get("sub_type") or "add"
                comment = info.get("comment") or ""

                sha_candidates = self._extract_sha_candidates(comment)
                logger.debug(
                    f"[å®¡é˜…åŠ ç¾¤] user={user_id}, flag_present={bool(flag)}, sha_candidates={sha_candidates}"
                )

                matched = False
                matched_prefix = None
                if sha_candidates:
                    for cand in sha_candidates:
                        if len(cand) >= 7 and any(s.startswith(cand) for s in recent_shas):
                            matched = True
                            matched_prefix = cand
                            break
                logger.debug(
                    f"[å®¡é˜…åŠ ç¾¤] user={user_id}, matched={matched}, matched_prefix={matched_prefix}"
                )

                if not flag:
                    results.append(f"{user_id}: ç”³è¯·ç¼ºå°‘å‡­æ®ï¼Œæ— æ³•å¤„ç†")
                    continue

                try:
                    await event.bot.set_group_add_request(
                        flag=flag,
                        sub_type=sub_type,
                        approve=matched,
                        reason=(
                            f"SHAåŒ¹é…: {matched_prefix}" if matched and matched_prefix else "SHAä¸æ­£ç¡®å‘¢ï¼Œå†ä»”ç»†æ£€æŸ¥ä¸€ä¸‹å§"
                        ),
                    )
                    if matched:
                        approved += 1
                        results.append(f"{user_id}: å·²æ‰¹å‡† (åŒ¹é… {matched_prefix})")
                    else:
                        rejected += 1
                        results.append(f"{user_id}: å·²æ‹’ç» (æœªåŒ¹é…)")
                    # æˆåŠŸåç§»é™¤ç¼“å­˜
                    if grp_id in self._pending_cache and user_id in self._pending_cache[grp_id]:
                        del self._pending_cache[grp_id][user_id]
                except Exception as e:
                    logger.error(f"å¤„ç†ç”³è¯·å¤±è´¥ user={user_id}: {e}")
                    results.append(f"{user_id}: å¤„ç†å¤±è´¥")

            # ä¿å­˜ç¼“å­˜å˜æ›´
            try:
                self._save_pending_cache()
            except Exception:
                pass

            yield event.plain_result(self._format_summary(approved, rejected, skipped_blacklist, results))
        except Exception as e:
            logger.error(f"å®¡é˜…åŠ ç¾¤æ‰§è¡Œå¼‚å¸¸: {e}")
            yield event.plain_result("æ‰§è¡Œå¼‚å¸¸ï¼Œè¯·ç¨åå†è¯•")

    @filter.platform_adapter_type(filter.PlatformAdapterType.AIOCQHTTP)
    @filter.event_message_type(filter.EventMessageType.ALL, priority=1)
    async def capture_group_add_requests(self, event: AiocqhttpMessageEvent):
        """å‚è€ƒ QQAdminï¼šç›‘å¬ OneBot è¯·æ±‚äº‹ä»¶ï¼Œç¼“å­˜ flag ä»¥ä¾¿ç¦»çº¿å®¡æ‰¹ã€‚"""
        try:
            raw = getattr(event.message_obj, "raw_message", None)
            if not isinstance(raw, dict):
                return
            if raw.get("post_type") != "request" or raw.get("request_type") != "group":
                return
            sub_type = raw.get("sub_type") or "add"
            if sub_type not in {"add", "invite"}:
                return
            group_id = raw.get("group_id")
            user_id = raw.get("user_id")
            flag = raw.get("flag")
            comment = raw.get("comment") or ""
            if group_id and user_id and flag:
                self._remember_request(str(group_id), str(user_id), str(flag), str(sub_type), str(comment))
                logger.debug(
                    f"[å®¡é˜…åŠ ç¾¤] ç¼“å­˜è¯·æ±‚: group_id={group_id}, user_id={user_id}, sub_type={sub_type}, flag_len={len(str(flag))}"
                )

                # è‡ªåŠ¨å®¡é˜…ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                if bool(self.config.get("auto_review_on_request", True)):
                    try:
                        # ç®¡ç†å‘˜/ç¾¤ä¸»æ ¡éªŒ
                        group = await event.get_group(group_id=str(group_id))
                        if not self._is_group_admin(event, group):
                            logger.debug(
                                f"[å®¡é˜…åŠ ç¾¤] auto-skip (not admin) group_id={group_id}, user_id={user_id}"
                            )
                            return
                        # é»‘åå•è·³è¿‡
                        if self._is_blacklisted(str(group_id), str(user_id)):
                            logger.debug(
                                f"[å®¡é˜…åŠ ç¾¤] auto-skip (blacklist) group_id={group_id}, user_id={user_id}"
                            )
                            return

                        # æ‹‰å–æœ€è¿‘æäº¤å¹¶åŒ¹é… SHA å‰ç¼€
                        recent_shas = [s.lower() for s in await self._fetch_recent_commit_shas()]
                        sha_candidates = self._extract_sha_candidates(str(comment))
                        matched = False
                        matched_prefix = None
                        for cand in sha_candidates:
                            if len(cand) >= 7 and any(s.startswith(cand) for s in recent_shas):
                                matched = True
                                matched_prefix = cand
                                break

                        await event.bot.set_group_add_request(
                            flag=str(flag),
                            sub_type=sub_type,
                            approve=matched,
                            reason=(
                                f"SHAåŒ¹é…: {matched_prefix}"
                                if matched and matched_prefix
                                else "ä¸å¯¹å“¦ï¼Œå†å¥½å¥½æƒ³æƒ³å§"
                            ),
                        )

                        # æˆåŠŸå¤„ç†åç§»é™¤ç¼“å­˜
                        gid = str(group_id)
                        uid = str(user_id)
                        if gid in self._pending_cache and uid in self._pending_cache[gid]:
                            del self._pending_cache[gid][uid]
                            self._save_pending_cache()

                        logger.debug(
                            f"[å®¡é˜…åŠ ç¾¤] auto-processed approve={matched} group_id={group_id}, user_id={user_id}, cand={matched_prefix}"
                        )
                    except Exception as e:
                        logger.error(f"[å®¡é˜…åŠ ç¾¤] auto-review å¼‚å¸¸: {e}")
        except Exception as e:
            logger.error(f"[å®¡é˜…åŠ ç¾¤] capture_group_add_requests å¼‚å¸¸: {e}")

    async def terminate(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†å·¥ä½œ"""
        logger.info("GitHub SHA æ’ä»¶å·²å¸è½½")
