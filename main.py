import aiohttp
import ssl
import certifi
import re
import os
import json
import time
import random
import asyncio
from datetime import datetime
from typing import List, Dict, Any

from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register, StarTools
from astrbot.api import logger, AstrBotConfig
from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import (
    AiocqhttpMessageEvent,
)


@register(
    "astrbot_plugin_sha",
    "ChuranNeko",
    "è·å–GitHubä»“åº“æœ€å5æ¬¡æäº¤SHAçš„æ’ä»¶",
    "1.4.1",
    "https://github.com/IGCrystal-NEO/astrbot_plugin_sha",
)

class GitHubShaPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        self._pending_cache: Dict[str, Dict[str, Dict[str, Any]]] = {}
        self._data_dir = str(StarTools.get_data_dir("astrbot_plugin_sha"))
        self._pending_path = os.path.join(self._data_dir, "pending_group_requests.json")
        self._error_count_path = os.path.join(self._data_dir, "error_counts.json")
        self._error_counts: Dict[str, Dict[str, Dict[str, int]]] = {}
        self._reset_task: asyncio.Task | None = None
        self._last_reset_date: str = ""

    async def initialize(self):
        try:
            os.makedirs(self._data_dir, exist_ok=True)
            if os.path.exists(self._pending_path):
                with open(self._pending_path, "r", encoding="utf-8") as f:
                    self._pending_cache = json.load(f)
            
            # åŠ è½½é”™è¯¯æ¬¡æ•°æ•°æ®
            if os.path.exists(self._error_count_path):
                with open(self._error_count_path, "r", encoding="utf-8") as f:
                    self._error_counts = json.load(f)
            
            # å¯åŠ¨å®šæ—¶é‡ç½®ä»»åŠ¡
            reset_hour = self.config.get("reset_hour", 4)
            if reset_hour >= 0:
                self._reset_task = asyncio.create_task(self._reset_scheduler())
                logger.info(f"[å®¡é˜…åŠ ç¾¤] å·²å¯åŠ¨å®šæ—¶é‡ç½®ä»»åŠ¡ï¼Œé‡ç½®æ—¶é—´ï¼šæ¯æ—¥ {reset_hour}:00")
        except Exception as e:
            logger.error(f"[å®¡é˜…åŠ ç¾¤] åŠ è½½å¾…å®¡ç¼“å­˜å¤±è´¥: {e}")

    def _save_pending_cache(self) -> None:
        try:
            with open(self._pending_path, "w", encoding="utf-8") as f:
                json.dump(self._pending_cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"[å®¡é˜…åŠ ç¾¤] ä¿å­˜å¾…å®¡ç¼“å­˜å¤±è´¥: {e}")
    
    def _save_error_counts(self) -> None:
        """ä¿å­˜é”™è¯¯æ¬¡æ•°æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            with open(self._error_count_path, "w", encoding="utf-8") as f:
                json.dump(self._error_counts, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"[å®¡é˜…åŠ ç¾¤] ä¿å­˜é”™è¯¯æ¬¡æ•°æ•°æ®å¤±è´¥: {e}")
    
    def _get_today_date(self) -> str:
        """è·å–ä»Šå¤©çš„æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)"""
        return datetime.now().strftime("%Y-%m-%d")
    
    def _get_error_count(self, group_id: str, user_id: str) -> int:
        """è·å–ç”¨æˆ·ä»Šæ—¥çš„é”™è¯¯æ¬¡æ•°"""
        today = self._get_today_date()
        return self._error_counts.get(str(group_id), {}).get(str(user_id), {}).get(today, 0)
    
    def _increment_error_count(self, group_id: str, user_id: str) -> int:
        """å¢åŠ ç”¨æˆ·ä»Šæ—¥çš„é”™è¯¯æ¬¡æ•°,è¿”å›å¢åŠ åçš„æ¬¡æ•°"""
        today = self._get_today_date()
        group_id = str(group_id)
        user_id = str(user_id)
        
        if group_id not in self._error_counts:
            self._error_counts[group_id] = {}
        if user_id not in self._error_counts[group_id]:
            self._error_counts[group_id][user_id] = {}
        
        current = self._error_counts[group_id][user_id].get(today, 0)
        self._error_counts[group_id][user_id][today] = current + 1
        self._save_error_counts()
        return current + 1
    
    def _is_over_max_attempts(self, group_id: str, user_id: str) -> bool:
        """æ£€æŸ¥ç”¨æˆ·ä»Šæ—¥æ˜¯å¦å·²è¶…è¿‡æœ€å¤§é”™è¯¯æ¬¡æ•°"""
        max_attempts = self.config.get("max_attempts", 3)
        if max_attempts <= 0:
            return False  # 0è¡¨ç¤ºä¸é™åˆ¶
        
        current_count = self._get_error_count(group_id, user_id)
        return current_count >= max_attempts
    
    async def _reset_scheduler(self) -> None:
        """å®šæ—¶é‡ç½®ä»»åŠ¡,æ¯æ—¥æŒ‡å®šæ—¶é—´é‡ç½®æ‰€æœ‰ç”¨æˆ·çš„é”™è¯¯æ¬¡æ•°"""
        while True:
            try:
                reset_hour = self.config.get("reset_hour", 4)
                if reset_hour < 0:
                    logger.info("[å®¡é˜…åŠ ç¾¤] é‡ç½®æ—¶é—´è®¾ç½®ä¸º -1,åœæ­¢å®šæ—¶é‡ç½®ä»»åŠ¡")
                    break
                
                now = datetime.now()
                today_reset_time = now.replace(hour=reset_hour, minute=0, second=0, microsecond=0)
                
                # å¦‚æœä»Šå¤©çš„é‡ç½®æ—¶é—´å·²è¿‡,è®¡ç®—åˆ°æ˜å¤©çš„é‡ç½®æ—¶é—´
                if now >= today_reset_time:
                    from datetime import timedelta
                    tomorrow_reset_time = today_reset_time + timedelta(days=1)
                    wait_seconds = (tomorrow_reset_time - now).total_seconds()
                else:
                    wait_seconds = (today_reset_time - now).total_seconds()
                
                logger.info(f"[å®¡é˜…åŠ ç¾¤] ä¸‹æ¬¡é‡ç½®æ—¶é—´: {wait_seconds / 3600:.2f} å°æ—¶å")
                await asyncio.sleep(wait_seconds)
                
                # æ‰§è¡Œé‡ç½®
                today = self._get_today_date()
                if today != self._last_reset_date:
                    logger.info(f"[å®¡é˜…åŠ ç¾¤] å¼€å§‹é‡ç½®é”™è¯¯æ¬¡æ•°è®¡æ•°å™¨ (æ—¥æœŸ: {today})")
                    # æ¸…ç©ºæ‰€æœ‰æ—§æ—¥æœŸçš„æ•°æ®
                    for group_id in list(self._error_counts.keys()):
                        for user_id in list(self._error_counts[group_id].keys()):
                            # åªä¿ç•™ä»Šå¤©çš„æ•°æ®
                            user_data = self._error_counts[group_id][user_id]
                            self._error_counts[group_id][user_id] = {
                                k: v for k, v in user_data.items() if k == today
                            }
                            # å¦‚æœç”¨æˆ·æ²¡æœ‰ä»Šå¤©çš„æ•°æ®,åˆ é™¤è¯¥ç”¨æˆ·
                            if not self._error_counts[group_id][user_id]:
                                del self._error_counts[group_id][user_id]
                        # å¦‚æœç¾¤ç»„æ²¡æœ‰ç”¨æˆ·,åˆ é™¤è¯¥ç¾¤ç»„
                        if not self._error_counts[group_id]:
                            del self._error_counts[group_id]
                    
                    self._save_error_counts()
                    self._last_reset_date = today
                    logger.info("[å®¡é˜…åŠ ç¾¤] é”™è¯¯æ¬¡æ•°è®¡æ•°å™¨é‡ç½®å®Œæˆ")
                
            except asyncio.CancelledError:
                logger.info("[å®¡é˜…åŠ ç¾¤] å®šæ—¶é‡ç½®ä»»åŠ¡å·²å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"[å®¡é˜…åŠ ç¾¤] å®šæ—¶é‡ç½®ä»»åŠ¡å¼‚å¸¸: {e}")
                await asyncio.sleep(3600)  # å‡ºé”™åç­‰å¾…1å°æ—¶å†è¯•

    def _remember_request(self, group_id: str, user_id: str, flag: str, sub_type: str, comment: str) -> None:
        group_id = str(group_id)
        user_id = str(user_id)
        self._pending_cache.setdefault(group_id, {})[user_id] = {
            "flag": flag,
            "sub_type": sub_type,
            "comment": comment or "",
            "ts": int(time.time()),
        }

        expire_before = int(time.time()) - 48 * 3600
        for gid in list(self._pending_cache.keys()):
            for uid in list(self._pending_cache[gid].keys()):
                if int(self._pending_cache[gid][uid].get("ts", 0)) < expire_before:
                    del self._pending_cache[gid][uid]
            if not self._pending_cache[gid]:
                del self._pending_cache[gid]
        self._save_pending_cache()

    def _get_cached_request(self, group_id: str, user_id: str) -> Dict[str, Any] | None:
        return self._pending_cache.get(str(group_id), {}).get(str(user_id))

    def _group_join_data_path(self) -> str:
        return os.path.join(str(StarTools.get_data_dir("astrbot_plugin_sha")), "group_join_data.json")

    def _load_group_join_blacklist(self) -> Dict[str, Any]:
        try:
            path = self._group_join_data_path()
            if os.path.exists(path):
                with open(path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    return data or {}
        except Exception as e:
            logger.error(f"[å®¡é˜…åŠ ç¾¤] è¯»å–é»‘åå•å¤±è´¥: {e}")
        return {}

    def _is_blacklisted(self, group_id: str, user_id: str) -> bool:
        data = self._load_group_join_blacklist()
        reject_ids: Dict[str, List[str]] = data.get("reject_ids", {})
        group_list = reject_ids.get(str(group_id), []) or []
        return str(user_id) in {str(x) for x in group_list}

    def _get_repo_cfg(self) -> tuple[str, str, int]:
        github_repo = self.config.get("github_repo", "AstrBotDevs/AstrBot")
        branch = self.config.get("branch", "master")
        commit_count = self.config.get("commit_count", 5)
        return github_repo, branch, commit_count

    def _is_group_admin(self, event: AiocqhttpMessageEvent, group) -> bool:
        if not group:
            return False
        self_id = str(event.get_self_id())
        admin_ids = [str(x) for x in (group.group_admins or [])]
        owner_id = str(group.group_owner) if group.group_owner else None
        return self_id in admin_ids or (owner_id and self_id == owner_id)

    @staticmethod
    def _match_sha_prefixes(candidates: List[str], recent_shas: List[str]) -> tuple[bool, str | None]:
        for cand in candidates:
            if len(cand) >= 7 and any(s.startswith(cand) for s in recent_shas):
                return True, cand
        return False, None

    def _format_summary(self, approved: int, rejected: int, skipped_blacklist: int, details: List[str]) -> str:
        if approved == 0 and rejected == 0:
            if details:
                return "\n".join(details)
            msg = "æ²¡æœ‰å¯å®¡é˜…çš„åŠ ç¾¤ç”³è¯·"
            if skipped_blacklist:
                msg += f"ï¼ˆå«é»‘åå•è·³è¿‡ {skipped_blacklist} é¡¹ï¼‰"
            return msg
        prefix = f"å®¡é˜…å®Œæˆï¼šæ‰¹å‡† {approved} é¡¹ï¼Œæ‹’ç» {rejected} é¡¹"
        if skipped_blacklist:
            prefix += f"ï¼Œè·³è¿‡ {skipped_blacklist} é¡¹ï¼ˆé»‘åå•ï¼‰"
        return prefix + ("\n" + "\n".join(details) if details else "")

    async def _review_request_core(
        self,
        event: AiocqhttpMessageEvent,
        group_id: str,
        user_id: str | None,
        flag: str | None,
        sub_type: str,
        comment: str,
        recent_shas: List[str],
    ) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„å•æ¡è¯·æ±‚å®¡é˜…æµç¨‹ï¼Œä¾›è‡ªåŠ¨/æ‰‹åŠ¨å¤ç”¨ã€‚

        è¿”å›ï¼š
          {
            'outcome': 'approved'|'rejected'|'no_flag'|'skipped_blacklist'|'over_limit'|'error',
            'matched_prefix': str|None,
            'message': str  # å¯ç”¨äºè¾“å‡ºçš„æ˜ç»†è¡Œï¼ˆéƒ¨åˆ† outcome å¯èƒ½ä¸ºç©ºï¼‰
            'error_count': int  # å½“å‰é”™è¯¯æ¬¡æ•°
          }
        """

        if user_id and self._is_blacklisted(group_id, user_id):
            return {"outcome": "skipped_blacklist", "matched_prefix": None, "message": "", "error_count": 0}

        # å…ˆæ£€æŸ¥ç”¨æˆ·ä»Šæ—¥æ˜¯å¦å·²è¶…è¿‡é”™è¯¯ä¸Šé™ (ä¸æ˜¯åˆšå¥½è¾¾åˆ°,è€Œæ˜¯å·²ç»è¶…è¿‡)
        if user_id and self._is_over_max_attempts(group_id, user_id):
            # å·²ç»è¶…è¿‡ä¸Šé™,éœ€è¦æ‹’ç»è¯·æ±‚å¹¶è®¾ç½®æ‹’ç»ç†ç”±
            if flag:
                try:
                    await event.bot.set_group_add_request(
                        flag=str(flag),
                        sub_type=sub_type or "add",
                        approve=False,
                        reason="è¯·æ˜å¤©å†æ¥ç­”é¢˜å“¦"
                    )
                except Exception as e:
                    logger.error(f"æ‹’ç»è¶…é™ç”¨æˆ·å¤±è´¥ user={user_id}, flag={flag}: {e}")
            
            return {
                "outcome": "over_limit",
                "matched_prefix": None,
                "message": f"{user_id}: ä»Šæ—¥é”™è¯¯æ¬¡æ•°å·²è¾¾ä¸Šé™,å·²é™é»˜æ‹’ç»",
                "error_count": self._get_error_count(group_id, user_id)
            }

        if not flag:
            return {
                "outcome": "no_flag",
                "matched_prefix": None,
                "message": f"{user_id}: ç”³è¯·ç¼ºå°‘å‡­æ®ï¼Œæ— æ³•å¤„ç†",
                "error_count": 0
            }

        sha_candidates = self._extract_sha_candidates(comment)
        matched, matched_prefix = self._match_sha_prefixes(sha_candidates, recent_shas)

        try:
            reject_no_sha_msgs = [
                "ä¸å¯¹å“¦ï¼Œå†å¥½å¥½æƒ³æƒ³å§ï½ä¸çŸ¥é“çš„è¯å¯ä»¥å» GitHub çœ‹çœ‹å“¦",
                "è¿˜å·®ç‚¹æ„æ€å‘¢ï¼Œå» GitHub æ£€æŸ¥ä¸€ä¸‹å†æ¥è¯•è¯•å§ï½",
                "æ²¡çœ‹åˆ°åƒæäº¤å·çš„ä¸œè¥¿å‘¢ï¼Œå» GitHub æ£€æŸ¥ä¸€ä¸‹å†æ¥å­ï½",
            ]
            reject_mismatch_msgs = [
                "çœ‹èµ·æ¥ä¸æ˜¯æœ€æ–°æäº¤çš„å‘¢ï¼Œå†æ ¸å¯¹ä¸€ä¸‹å§ï½",
                "å¥½åƒå¯¹ä¸ä¸Šæœ€æ–°æäº¤è€¶ï¼Œç¡®è®¤ä¸‹å†è¯•ï½",
            ]

            if matched and matched_prefix:
                reason_text = ""
            else:
                reason_text = (
                    random.choice(reject_no_sha_msgs)
                    if not sha_candidates
                    else random.choice(reject_mismatch_msgs)
                )

            await event.bot.set_group_add_request(
                flag=str(flag),
                sub_type=sub_type or "add",
                approve=matched,
                reason=reason_text,
            )
            
            if matched:
                return {
                    "outcome": "approved",
                    "matched_prefix": matched_prefix,
                    "message": f"{user_id}: å·²æ‰¹å‡† (åŒ¹é… {matched_prefix})",
                    "error_count": 0
                }
            else:
                # å›ç­”é”™è¯¯,å¢åŠ é”™è¯¯æ¬¡æ•°
                if user_id:
                    error_count = self._increment_error_count(group_id, user_id)
                    max_attempts = self.config.get("max_attempts", 3)
                    
                    # æ£€æŸ¥æ˜¯å¦åˆšå¥½è¾¾åˆ°ä¸Šé™(è¿™æ˜¯æœ€åä¸€æ¬¡æœºä¼š)
                    if max_attempts > 0 and error_count == max_attempts:
                        return {
                            "outcome": "rejected_final",  # æ–°çŠ¶æ€: æœ€åä¸€æ¬¡æ‹’ç»,éœ€è¦å‘é€ç‰¹æ®Šæ¶ˆæ¯
                            "matched_prefix": matched_prefix,
                            "message": f"{user_id}: å·²æ‹’ç» (è¾¾åˆ°é”™è¯¯ä¸Šé™)",
                            "error_count": error_count
                        }
                else:
                    error_count = 0
                
                return {
                    "outcome": "rejected",
                    "matched_prefix": matched_prefix,
                    "message": f"{user_id}: å·²æ‹’ç» (æœªåŒ¹é…)",
                    "error_count": error_count
                }
        except Exception as e:
            logger.error(f"å¤„ç†ç”³è¯·å¤±è´¥ user={user_id}, flag={flag}: {e}")
            return {
                "outcome": "error",
                "matched_prefix": matched_prefix,
                "message": f"{user_id}: å¤„ç†å¤±è´¥",
                "error_count": 0
            }

    @filter.regex(r"(?i)\bhash\b")
    async def on_hash_keyword(self, event: AstrMessageEvent):
        """å…¨å±€ç›‘å¬ï¼šæ¶ˆæ¯åŒ…å«å•è¯ 'hash' æ—¶è§¦å‘ï¼ˆä¸ä¾èµ–å”¤é†’å‰ç¼€ï¼‰"""
        async for res in self.get_github_sha(event):
            yield res

    @filter.command("sha")
    async def get_github_sha(self, event: AstrMessageEvent):
        """è·å–GitHubä»“åº“æŒ‡å®šåˆ†æ”¯çš„æœ€æ–°æäº¤SHA"""
        try:
            github_repo, branch, commit_count = self._get_repo_cfg()
            github_api_url = f"https://api.github.com/repos/{github_repo}/commits"

            if github_repo == "AstrBotDevs/AstrBot":
                reminder_msg = (
                    f"ğŸ“Œ å½“å‰ä½¿ç”¨é»˜è®¤ä»“åº“: {github_repo}\n"
                    "ğŸ’¡ æç¤º: å¯åœ¨æ’ä»¶ç®¡ç†é¡µé¢é…ç½®å…¶ä»–GitHubä»“åº“åœ°å€\n"
                    "æ ¼å¼: owner/repo (ä¾‹å¦‚: microsoft/vscode)"
                )
                yield event.plain_result(reminder_msg)

            logger.debug(f"å¼€å§‹è·å– {github_repo} ä»“åº“çš„æäº¤SHA...")

            ssl_ctx = ssl.create_default_context(cafile=certifi.where())

            connector = aiohttp.TCPConnector(ssl=ssl_ctx)
            async with aiohttp.ClientSession(connector=connector) as session:
                params = {"sha": branch, "per_page": commit_count}

                async with session.get(github_api_url, params=params) as response:
                    if response.status == 200:
                        commits = await response.json()

                        if not commits:
                            yield event.plain_result("âŒ æœªæ‰¾åˆ°ä»»ä½•æäº¤è®°å½•")
                            return

                        result_lines = [
                            f"ğŸ” {github_repo} ä»“åº“ ({branch} åˆ†æ”¯) æœ€å{commit_count}æ¬¡æäº¤ SHAï¼š\n"
                        ]

                        for i, commit in enumerate(commits, 1):
                            sha = commit["sha"]
                            message = commit["commit"]["message"].split("\n")[
                                0
                            ]
                            author = commit["commit"]["author"]["name"]
                            date = commit["commit"]["author"]["date"][
                                :10
                            ]

                            result_lines.append(f"{i}. {sha} - {message}")
                            result_lines.append(f"   ä½œè€…: {author} | æ—¥æœŸ: {date}\n")

                        result_text = "\n".join(result_lines)
                        yield event.plain_result(result_text)

                        logger.debug(f"æˆåŠŸè·å– {github_repo} çš„GitHubæäº¤SHA")

                    else:
                        error_msg = f"GitHub API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}"
                        logger.error(error_msg)
                        yield event.plain_result(f"âŒ {error_msg}")

        except aiohttp.ClientError as e:
            error_msg = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}"
            logger.error(error_msg)
            yield event.plain_result(f"âŒ {error_msg}")

        except Exception as e:
            error_msg = f"è·å–æäº¤SHAæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(error_msg)
            yield event.plain_result(f"âŒ {error_msg}")

    async def _fetch_recent_commit_shas(self) -> List[str]:
        """è¿”å›æœ€è¿‘é…ç½®æ•°é‡çš„æäº¤ SHA åˆ—è¡¨ï¼ˆå®Œæ•´ 40 ä½ï¼‰ã€‚"""
        github_repo = self.config.get("github_repo", "AstrBotDevs/AstrBot")
        branch = self.config.get("branch", "master")
        commit_count = self.config.get("commit_count", 5)
        github_api_url = f"https://api.github.com/repos/{github_repo}/commits"

        ssl_ctx = ssl.create_default_context(cafile=certifi.where())
        connector = aiohttp.TCPConnector(ssl=ssl_ctx)
        async with aiohttp.ClientSession(connector=connector) as session:
            params = {"sha": branch, "per_page": commit_count}
            async with session.get(github_api_url, params=params) as response:
                if response.status != 200:
                    raise RuntimeError(
                        f"GitHub API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}"
                    )
                commits = await response.json()
                return [c["sha"] for c in commits if "sha" in c]

    @staticmethod
    def _extract_sha_candidates(text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å¯èƒ½çš„ SHA å‰ç¼€ï¼ˆè‡³å°‘7ä½ï¼‰ã€‚"""
        if not text:
            return []
        candidates = re.findall(r"\b[a-fA-F0-9]{7,40}\b", text)

        dedup = []
        for c in candidates:
            c = c.lower()
            if c not in dedup:
                dedup.append(c)
        return dedup

    # å·²ç§»é™¤æ‰‹åŠ¨"å®¡é˜…åŠ ç¾¤"å‘½ä»¤ï¼Œæ‰€æœ‰åŠ ç¾¤è¯·æ±‚é€šè¿‡è‡ªåŠ¨å®¡é˜…å¤„ç†

    @filter.platform_adapter_type(filter.PlatformAdapterType.AIOCQHTTP)
    @filter.event_message_type(filter.EventMessageType.ALL, priority=1)
    async def capture_group_add_requests(self, event: AiocqhttpMessageEvent):
        """ç›‘å¬ OneBot è¯·æ±‚äº‹ä»¶ï¼Œç¼“å­˜ flag ä»¥ä¾¿ç¦»çº¿å®¡æ‰¹ã€‚"""
        try:
            raw = getattr(event.message_obj, "raw_message", None)
            if not isinstance(raw, dict):
                return
            if raw.get("post_type") != "request" or raw.get("request_type") != "group":
                return
            sub_type = raw.get("sub_type") or "add"
            if sub_type not in {"add", "invite"}:
                return
            group_id = raw.get("group_id")
            user_id = raw.get("user_id")
            flag = raw.get("flag")
            comment = raw.get("comment") or ""
            if group_id and user_id and flag:
                self._remember_request(str(group_id), str(user_id), str(flag), str(sub_type), str(comment))
                logger.debug(
                    f"[å®¡é˜…åŠ ç¾¤] ç¼“å­˜è¯·æ±‚: group_id={group_id}, user_id={user_id}, sub_type={sub_type}, flag_len={len(str(flag))}"
                )

                if bool(self.config.get("auto_review_on_request", True)):
                    try:
                        # æ£€æŸ¥ç¾¤èŠç™½åå•
                        enabled_groups = self.config.get("enabled_groups", [])
                        if enabled_groups and str(group_id) not in [str(g) for g in enabled_groups]:
                            logger.debug(
                                f"[å®¡é˜…åŠ ç¾¤] auto-skip (not in enabled_groups) group_id={group_id}"
                            )
                            return

                        group = await event.get_group(group_id=str(group_id))
                        if not self._is_group_admin(event, group):
                            logger.debug(
                                f"[å®¡é˜…åŠ ç¾¤] auto-skip (not admin) group_id={group_id}, user_id={user_id}"
                            )
                            return

                        if self._is_blacklisted(str(group_id), str(user_id)):
                            logger.debug(
                                f"[å®¡é˜…åŠ ç¾¤] auto-skip (blacklist) group_id={group_id}, user_id={user_id}"
                            )
                            return

                        recent_shas = [s.lower() for s in await self._fetch_recent_commit_shas()]
                        outcome = await self._review_request_core(
                            event=event,
                            group_id=str(group_id),
                            user_id=str(user_id),
                            flag=str(flag),
                            sub_type=sub_type,
                            comment=str(comment),
                            recent_shas=recent_shas,
                        )

                        gid = str(group_id)
                        uid = str(user_id)
                        if gid in self._pending_cache and uid in self._pending_cache[gid]:
                            del self._pending_cache[gid][uid]
                            self._save_pending_cache()

                        try:
                            avatar_url = f"https://q1.qlogo.cn/g?b=qq&nk={user_id}&s=100"
                            
                            if outcome["outcome"] == "over_limit":
                                # å·²ç»è¶…è¿‡é”™è¯¯æ¬¡æ•°ä¸Šé™,é™é»˜æ‹’ç»,ä¸å‘é€ä»»ä½•æ¶ˆæ¯
                                logger.info(f"[å®¡é˜…åŠ ç¾¤] ç”¨æˆ· {user_id} å·²è¶…è¿‡é”™è¯¯ä¸Šé™,é™é»˜æ‹’ç»")
                            elif outcome["outcome"] == "rejected_final":
                                # æœ€åä¸€æ¬¡é”™è¯¯(åˆšå¥½è¾¾åˆ°ä¸Šé™),å‘é€ç‰¹æ®Šæç¤ºæ¶ˆæ¯
                                error_count = outcome.get("error_count", 0)
                                notice = f"[CQ:image,file={avatar_url}]\nç”¨æˆ· {user_id} å·²ç»è¿ç»­{error_count}æ¬¡å›ç­”é”™è¯¯å•¦ï¼Œè¿™ä¸ªç¬¨è›‹ä»Šå¤©è¿›ä¸äº†è¿™ä¸ªç¾¤å•¦"
                                await event.bot.send_group_msg(group_id=gid, message=notice)
                                logger.info(f"[å®¡é˜…åŠ ç¾¤] ç”¨æˆ· {user_id} è¾¾åˆ°é”™è¯¯ä¸Šé™ ({error_count}æ¬¡)")
                            elif outcome["outcome"] == "approved":
                                # é€šè¿‡ç”³è¯·
                                matched = outcome.get("matched_prefix") or ""
                                notice = (
                                    f"å®¡é˜…ç»“æœï¼šå·²é€šè¿‡ç”¨æˆ· {user_id} çš„åŠ ç¾¤ç”³è¯·"
                                    + (f"ï¼ˆåŒ¹é…æäº¤ {matched[:7]}ï¼‰" if matched else "")
                                    + "ï¼Œæ¬¢è¿åŠ å…¥ï¼"
                                )
                                message_with_avatar = f"[CQ:image,file={avatar_url}]\n{notice}"
                                await event.bot.send_group_msg(group_id=gid, message=message_with_avatar)
                            elif outcome["outcome"] == "rejected":
                                # æ‹’ç»ç”³è¯·,æ˜¾ç¤ºå½“å‰é”™è¯¯æ¬¡æ•°å’Œå‰©ä½™æœºä¼š
                                error_count = outcome.get("error_count", 0)
                                max_attempts = self.config.get("max_attempts", 3)
                                attempts_info = ""
                                if max_attempts > 0:
                                    remaining = max_attempts - error_count
                                    if remaining > 0:
                                        attempts_info = f"\nå‰©ä½™å°è¯•æœºä¼šï¼š{remaining}æ¬¡"
                                
                                notice = (
                                    f"å®¡é˜…ç»“æœï¼šå·²æ‹’ç»ç”¨æˆ· {user_id} çš„åŠ ç¾¤ç”³è¯·\n"
                                    f"{(comment or '').strip() or 'æ— '}"
                                    f"{attempts_info}"
                                )
                                message_with_avatar = f"[CQ:image,file={avatar_url}]\n{notice}"
                                await event.bot.send_group_msg(group_id=gid, message=message_with_avatar)

                        except Exception as e:
                            logger.error(f"[å®¡é˜…åŠ ç¾¤] å‘é€ç¾¤å†…é€šçŸ¥å¤±è´¥ group_id={group_id}, user_id={user_id}: {e}")

                        logger.debug(f"[å®¡é˜…åŠ ç¾¤] auto-processed outcome={outcome['outcome']} group_id={group_id}, user_id={user_id}")
                    except Exception as e:
                        logger.error(f"[å®¡é˜…åŠ ç¾¤] auto-review å¼‚å¸¸: {e}")
        except Exception as e:
            logger.error(f"[å®¡é˜…åŠ ç¾¤] capture_group_add_requests å¼‚å¸¸: {e}")

    async def terminate(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†å·¥ä½œ"""
        if self._reset_task and not self._reset_task.done():
            self._reset_task.cancel()
            try:
                await self._reset_task
            except asyncio.CancelledError:
                pass
            logger.info("[å®¡é˜…åŠ ç¾¤] å·²å–æ¶ˆå®šæ—¶é‡ç½®ä»»åŠ¡")
        logger.info("GitHub SHA æ’ä»¶å·²å¸è½½")
